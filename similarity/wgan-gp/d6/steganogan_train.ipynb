{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYnJJYUxbdua"
   },
   "source": [
    "# SteganoGAN in Keras\n",
    "This notebook contains code attempting to reimplement SteganoGAN in Keras, for the purpose of better understanding (and scrutinizing) it.\n",
    "\n",
    "*Based on https://github.com/DAI-Lab/SteganoGAN/tree/master/steganogan*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OTRQl5_KUxUA"
   },
   "source": [
    "### Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QbnEM8Oubduh"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy, MeanSquaredError\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "from callbacks import SaveImages\n",
    "\n",
    "from resnet_steganogan_gp import SteganoGAN\n",
    "from models import DenseEncoder, DenseDecoder, Critic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MESSAGE_DEPTH = 6\n",
    "BATCH_SIZE = 4\n",
    "IMAGE_HEIGHT = 360\n",
    "IMAGE_WIDTH = 360\n",
    "IMAGE_CHANNELS = 3\n",
    "IMAGE_SHAPE = (IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS)\n",
    "\n",
    "MODEL_PATH = 'SteganoGAN.weights.h5'\n",
    "LOGS_PATH = 'SteganoGAN.csv'\n",
    "CALLBACK_IMAGES_PATH = 'images/callback'\n",
    "CALLBACK_IMAGES_OUTPUT_PATH = 'epoch_images'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model for future train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = DenseEncoder(MESSAGE_DEPTH)\n",
    "decoder = DenseDecoder(MESSAGE_DEPTH)\n",
    "critic = Critic()\n",
    "\n",
    "encoder.build(input_shape=[(None, None, None, IMAGE_CHANNELS), (None, None, None, MESSAGE_DEPTH)])\n",
    "decoder.build(input_shape=(None, None, None, IMAGE_CHANNELS))\n",
    "critic.build(input_shape=(None, None, None, IMAGE_CHANNELS))\n",
    "\n",
    "stegano_gan = SteganoGAN(\n",
    "  encoder=encoder,\n",
    "  decoder=decoder,\n",
    "  critic=critic,\n",
    "  data_depth=MESSAGE_DEPTH,\n",
    "  image_shape=IMAGE_SHAPE\n",
    ")\n",
    "\n",
    "stegano_gan.build(input_shape=[(None, None, None, IMAGE_CHANNELS), (None, None, None, MESSAGE_DEPTH)])\n",
    "\n",
    "if MODEL_PATH is not None and os.path.exists(MODEL_PATH):\n",
    "  stegano_gan.load_weights(MODEL_PATH)\n",
    "  print(f'Model loaded from {MODEL_PATH}')\n",
    "\n",
    "stegano_gan.compile(\n",
    "  encoder_decoder_optimizer  = Adam(learning_rate=1e-4),\n",
    "  critic_optimizer           = Adam(learning_rate=1e-4, beta_1=0.5, beta_2=0.9),\n",
    "  similarity_loss_fn         = MeanSquaredError(),\n",
    "  decoder_loss_fn            = BinaryCrossentropy(from_logits=True)\n",
    ")\n",
    "\n",
    "stegano_gan.summary()\n",
    "stegano_gan.encoder.summary()\n",
    "stegano_gan.decoder.summary()\n",
    "stegano_gan.critic.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download div2k dataset and complete it with random message dataset of {0, 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Load DIV2K dataset\n",
    "ds_div2k = tfds.load('div2k', shuffle_files=True)\n",
    "\n",
    "# Extract and preprocess high-resolution images\n",
    "def preprocess_hr(image):\n",
    "    image = tf.image.resize(image, (IMAGE_HEIGHT, IMAGE_WIDTH))  # Resize to target shape\n",
    "    image = tf.cast(image, tf.float32)      # Convert to float\n",
    "    image = (image / 127.5) - 1.0           # Normalize to [-1, 1]\n",
    "    return image\n",
    "\n",
    "train_image_ds = ds_div2k['train'].map(lambda x: preprocess_hr(x['hr']), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_image_ds = ds_div2k['validation'].map(lambda x: preprocess_hr(x['hr']), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# Batch datasets\n",
    "train_ds = train_image_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = val_image_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stegano_gan.fit(train_ds, epochs=10, validation_data=val_ds, initial_epoch=0, callbacks=[\n",
    "#   CSVLogger(LOGS_PATH, append=True),\n",
    "#   ModelCheckpoint(MODEL_PATH, monitor='encoder_decoder_total_loss', mode='min', save_weights_only=True),\n",
    "#   SaveImages(MESSAGE_DEPTH, IMAGE_SHAPE, CALLBACK_IMAGES_PATH, CALLBACK_IMAGES_OUTPUT_PATH)\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluated_metrics = stegano_gan.evaluate(val_ds)\n",
    "\n",
    "metrics_names = [\n",
    "  'encoder_decoder_total_loss',\n",
    "  'critic_loss',\n",
    "  'similarity_loss',\n",
    "  'decoder_loss',\n",
    "  'decoder_accuracy',\n",
    "  'realism_loss',\n",
    "  'psnr',\n",
    "  'ssim'\n",
    "]\n",
    "\n",
    "for key, value in zip(metrics_names, evaluated_metrics):\n",
    "  print(f'{key}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%rm -rf epoch_images/\n",
    "#%rm -rf SteganoGAN.weights.h5\n",
    "#%rm -rf SteganoGAN.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSNR between original and blurred image: 22.734779357910156 dB\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load image1\n",
    "image_path = 'images/callback/image1.png'\n",
    "image1 = tf.io.read_file(image_path)\n",
    "image1 = tf.image.decode_jpeg(image1, channels=3)\n",
    "image1 = tf.image.convert_image_dtype(image1, dtype=tf.float32)\n",
    "\n",
    "# Apply Gaussian blur to the image\n",
    "blurred_image = tf.image.resize(image1, (image1.shape[0] // 2, image1.shape[1] // 2))\n",
    "blurred_image = tf.image.resize(blurred_image, image1.shape[:2])\n",
    "\n",
    "# Compute PSNR\n",
    "psnr_original_vs_blurred = tf.image.psnr(image1, blurred_image, max_val=1.0)\n",
    "\n",
    "print(f\"PSNR between original and blurred image: {psnr_original_vs_blurred.numpy()} dB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSNR between original and modified image: 74.87420654296875 dB\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the original image\n",
    "image_path = \"images/callback/image1.png\"\n",
    "original_image = tf.io.read_file(image_path)\n",
    "original_image = tf.image.decode_png(original_image, channels=3)\n",
    "original_image = tf.image.convert_image_dtype(original_image, dtype=tf.float32)\n",
    "\n",
    "# Change one pixel (e.g., at position (0, 0))\n",
    "modified_image = original_image.numpy()  # Convert to numpy array to modify pixel\n",
    "modified_image[0, 0] += 0.1  # Modify pixel value\n",
    "modified_image = tf.convert_to_tensor(modified_image, dtype=tf.float32)  # Convert back to tensor\n",
    "\n",
    "# Compute PSNR\n",
    "psnr_value = tf.image.psnr(original_image, modified_image, max_val=1.0)\n",
    "\n",
    "print(f\"PSNR between original and modified image: {psnr_value.numpy()} dB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "steganogan_keras.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/jnickg/steganet/blob/main/steganogan_keras.ipynb",
     "timestamp": 1710610773710
    }
   ]
  },
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
